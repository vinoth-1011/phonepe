{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f58328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pulse' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PhonePe/pulse.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e8853f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uttar-pradesh',\n",
       " 'lakshadweep',\n",
       " 'jharkhand',\n",
       " 'odisha',\n",
       " 'himachal-pradesh',\n",
       " 'kerala',\n",
       " 'bihar',\n",
       " 'tripura',\n",
       " 'madhya-pradesh',\n",
       " 'karnataka',\n",
       " 'nagaland',\n",
       " 'west-bengal',\n",
       " 'tamil-nadu',\n",
       " 'dadra-&-nagar-haveli-&-daman-&-diu',\n",
       " 'manipur',\n",
       " 'jammu-&-kashmir',\n",
       " 'meghalaya',\n",
       " 'rajasthan',\n",
       " 'uttarakhand',\n",
       " 'ladakh',\n",
       " 'chhattisgarh',\n",
       " 'arunachal-pradesh',\n",
       " 'puducherry',\n",
       " 'sikkim',\n",
       " 'gujarat',\n",
       " 'maharashtra',\n",
       " 'andhra-pradesh',\n",
       " 'telangana',\n",
       " 'assam',\n",
       " 'andaman-&-nicobar-islands',\n",
       " 'chandigarh',\n",
       " 'mizoram',\n",
       " 'delhi',\n",
       " 'goa',\n",
       " 'punjab',\n",
       " 'haryana']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path=\"/workspaces/phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "Agg_state_list=os.listdir(path)\n",
    "Agg_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file saved as 'aggregated_transaction_data.csv'\n"
     ]
    }
   ],
   "source": [
    "#Aggregated_Transaction\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "#This is to direct the path to get the data as states\n",
    "\n",
    "path=\"/workspaces/phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "Agg_state_list=os.listdir(path)\n",
    "Agg_state_list\n",
    "#Agg_state_list--> to get the list of states in India\n",
    "\n",
    "#<------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------>#\n",
    "\n",
    "#This is to extract the data's to create a dataframe\n",
    "\n",
    "clm={'State':[], 'Year':[],'Quarter':[],'Transaction_type':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "\n",
    "for i in Agg_state_list:\n",
    "    p_i=path+i+\"/\"\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+\"/\"\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for z in D['data']['transactionData']:\n",
    "              Name=z['name']\n",
    "              count=z['paymentInstruments'][0]['count']\n",
    "              amount=z['paymentInstruments'][0]['amount']\n",
    "              clm['Transaction_type'].append(Name)\n",
    "              clm['Transaction_count'].append(count)\n",
    "              clm['Transaction_amount'].append(amount)\n",
    "              clm['State'].append(i)\n",
    "              clm['Year'].append(j)\n",
    "              clm['Quarter'].append(int(k.strip('.json')))\n",
    "#Succesfully created a dataframe\n",
    "Agg_Trans=pd.DataFrame(clm)\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "Agg_Trans.to_csv(\"/workspaces/phonepe/csv_data/aggregated_transaction_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV file saved as 'aggregated_transaction_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9165d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file saved as 'aggregated_insurance_data.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Transaction_type</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>74194</td>\n",
       "      <td>122522457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>78940</td>\n",
       "      <td>121483170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>73080</td>\n",
       "      <td>127110494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>92125</td>\n",
       "      <td>165509877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>55133</td>\n",
       "      <td>77434953.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>50391</td>\n",
       "      <td>81816509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>58808</td>\n",
       "      <td>94316512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>6321</td>\n",
       "      <td>1179814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>7139</td>\n",
       "      <td>1884868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>8283</td>\n",
       "      <td>5974278.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Year  Quarter Transaction_type  Transaction_count  \\\n",
       "0    uttar-pradesh  2023        2        Insurance              74194   \n",
       "1    uttar-pradesh  2023        3        Insurance              78940   \n",
       "2    uttar-pradesh  2023        1        Insurance              73080   \n",
       "3    uttar-pradesh  2023        4        Insurance              92125   \n",
       "4    uttar-pradesh  2022        2        Insurance              55133   \n",
       "..             ...   ...      ...              ...                ...   \n",
       "677        haryana  2024        1        Insurance              50391   \n",
       "678        haryana  2024        4        Insurance              58808   \n",
       "679        haryana  2020        2        Insurance               6321   \n",
       "680        haryana  2020        3        Insurance               7139   \n",
       "681        haryana  2020        4        Insurance               8283   \n",
       "\n",
       "     Transaction_amount  \n",
       "0           122522457.0  \n",
       "1           121483170.0  \n",
       "2           127110494.0  \n",
       "3           165509877.0  \n",
       "4            77434953.0  \n",
       "..                  ...  \n",
       "677          81816509.0  \n",
       "678          94316512.0  \n",
       "679           1179814.0  \n",
       "680           1884868.0  \n",
       "681           5974278.0  \n",
       "\n",
       "[682 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregated_insurance\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to insurance data\n",
    "path = \"/workspaces/phonepe/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Prepare dictionary\n",
    "clm = {'State': [], 'Year': [], 'Quarter': [], 'Transaction_type': [],\n",
    "       'Transaction_count': [], 'Transaction_amount': []}\n",
    "\n",
    "# Loop through states → years → quarters\n",
    "for i in Agg_state_list:\n",
    "    p_i = path + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            with open(p_k, 'r') as Data:\n",
    "                D = json.load(Data)\n",
    "            for z in D['data']['transactionData']:\n",
    "                Name = z['name']\n",
    "                count = z['paymentInstruments'][0]['count']\n",
    "                amount = z['paymentInstruments'][0]['amount']\n",
    "                clm['Transaction_type'].append(Name)\n",
    "                clm['Transaction_count'].append(count)\n",
    "                clm['Transaction_amount'].append(amount)\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(int(k.strip('.json')))\n",
    "\n",
    "# Create DataFrame\n",
    "Agg_Insu = pd.DataFrame(clm)\n",
    "\n",
    "# Save to CSV\n",
    "Agg_Insu.to_csv(\"/workspaces/phonepe/csv_data/aggregated_insurance_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV file saved as 'aggregated_insurance_data.csv'\")\n",
    "Agg_Insu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated_user\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to user data\n",
    "path = \"/workspaces/phonepe/pulse/data/aggregated/user/country/india/state\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Prepare dictionary for DataFrame\n",
    "clm = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'Brand': [],\n",
    "    'Transaction_count': [],\n",
    "    'Transaction_percentage': []\n",
    "}\n",
    "\n",
    "# Loop through states → years → quarters\n",
    "for i in Agg_state_list:\n",
    "    p_i = os.path.join(path, i)\n",
    "    if not os.path.exists(p_i):\n",
    "        print(f\"⚠️ Skipping missing state folder: {p_i}\")\n",
    "        continue\n",
    "\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        if not os.path.exists(p_j):\n",
    "            print(f\"⚠️ Skipping missing year folder: {p_j}\")\n",
    "            continue\n",
    "\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            if not os.path.isfile(p_k):\n",
    "                print(f\"⚠️ Skipping missing file: {p_k}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(p_k, 'r') as Data:\n",
    "                    D = json.load(Data)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {p_k}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Get usersByDevice safely\n",
    "            users_by_device = D.get('data', {}).get('usersByDevice', [])\n",
    "            if not users_by_device:\n",
    "                print(f\"⚠️ No 'usersByDevice' data in: {p_k}\")\n",
    "                continue\n",
    "\n",
    "            # Append data\n",
    "            for z in users_by_device:\n",
    "                clm['Brand'].append(z.get('brand', 'Unknown'))\n",
    "                clm['Transaction_count'].append(z.get('count', 0))\n",
    "                clm['Transaction_percentage'].append(z.get('percentage', 0))\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(int(k.strip('.json')))\n",
    "\n",
    "# Create DataFrame\n",
    "Agg_Use = pd.DataFrame(clm)\n",
    "\n",
    "# Save to CSV\n",
    "Agg_Use.to_csv(\"/workspaces/phonepe/csv_data/aggregated_user_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV file saved as 'aggregated_user_data.csv'\")\n",
    "Agg_Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4800d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file saved as 'map_transaction_data.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>District_State_Name</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>amethi district</td>\n",
       "      <td>7435760</td>\n",
       "      <td>1.282682e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>siddharthnagar district</td>\n",
       "      <td>10401429</td>\n",
       "      <td>2.076956e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>auraiya district</td>\n",
       "      <td>6051986</td>\n",
       "      <td>9.963270e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>sambhal district</td>\n",
       "      <td>8572592</td>\n",
       "      <td>1.594887e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>kanpur nagar district</td>\n",
       "      <td>33104317</td>\n",
       "      <td>5.216827e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20599</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>panipat district</td>\n",
       "      <td>3059943</td>\n",
       "      <td>7.874715e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20600</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>gurugram district</td>\n",
       "      <td>28192581</td>\n",
       "      <td>3.562961e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20601</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>kaithal district</td>\n",
       "      <td>959377</td>\n",
       "      <td>2.945844e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20602</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>kurukshetra district</td>\n",
       "      <td>1721950</td>\n",
       "      <td>4.141680e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20603</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>jhajjar district</td>\n",
       "      <td>2429140</td>\n",
       "      <td>5.544973e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20604 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               State  Year  Quarter      District_State_Name  \\\n",
       "0      uttar-pradesh  2023        2          amethi district   \n",
       "1      uttar-pradesh  2023        2  siddharthnagar district   \n",
       "2      uttar-pradesh  2023        2         auraiya district   \n",
       "3      uttar-pradesh  2023        2         sambhal district   \n",
       "4      uttar-pradesh  2023        2    kanpur nagar district   \n",
       "...              ...   ...      ...                      ...   \n",
       "20599        haryana  2020        4         panipat district   \n",
       "20600        haryana  2020        4        gurugram district   \n",
       "20601        haryana  2020        4         kaithal district   \n",
       "20602        haryana  2020        4     kurukshetra district   \n",
       "20603        haryana  2020        4         jhajjar district   \n",
       "\n",
       "       Transaction_count  Transaction_amount  \n",
       "0                7435760        1.282682e+10  \n",
       "1               10401429        2.076956e+10  \n",
       "2                6051986        9.963270e+09  \n",
       "3                8572592        1.594887e+10  \n",
       "4               33104317        5.216827e+10  \n",
       "...                  ...                 ...  \n",
       "20599            3059943        7.874715e+09  \n",
       "20600           28192581        3.562961e+10  \n",
       "20601             959377        2.945844e+09  \n",
       "20602            1721950        4.141680e+09  \n",
       "20603            2429140        5.544973e+09  \n",
       "\n",
       "[20604 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Map-Transaction\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to transaction data\n",
    "path = \"/workspaces/phonepe/pulse/data/map/transaction/hover/country/india/state\"\n",
    "Map_state_list = os.listdir(path)  # ✅ Corrected variable name\n",
    "\n",
    "# Prepare dictionary for DataFrame\n",
    "clm = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'District_State_Name': [],\n",
    "    'Transaction_count': [],\n",
    "    'Transaction_amount': []\n",
    "}\n",
    "\n",
    "for i in Map_state_list:  # ✅ Now using the right variable\n",
    "    p_i = os.path.join(path, i)\n",
    "    if not os.path.exists(p_i):\n",
    "        print(f\"⚠️ Skipping missing state folder: {p_i}\")\n",
    "        continue\n",
    "\n",
    "    Map_yr = os.listdir(p_i)\n",
    "    for j in Map_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        if not os.path.exists(p_j):\n",
    "            continue\n",
    "\n",
    "        Map_yr_list = os.listdir(p_j)\n",
    "        for k in Map_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            if not os.path.isfile(p_k):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(p_k, 'r') as Data:\n",
    "                    D = json.load(Data)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {p_k}: {e}\")\n",
    "                continue\n",
    "\n",
    "            hover_data_list = D.get('data', {}).get('hoverDataList', [])\n",
    "            if not hover_data_list:\n",
    "                print(f\"⚠️ No 'hoverDataList' data in: {p_k}\")\n",
    "                continue\n",
    "\n",
    "            for entry in hover_data_list:\n",
    "                name = entry.get('name', 'Unknown')\n",
    "                metric = entry.get('metric', [])\n",
    "                if metric:\n",
    "                    count = metric[0].get('count', 0)\n",
    "                    amount = metric[0].get('amount', 0)\n",
    "                else:\n",
    "                    count, amount = 0, 0\n",
    "\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(int(k.strip('.json')))\n",
    "                clm['District_State_Name'].append(name)\n",
    "                clm['Transaction_count'].append(count)\n",
    "                clm['Transaction_amount'].append(amount)\n",
    "\n",
    "# Create DataFrame\n",
    "Map_Trans = pd.DataFrame(clm)\n",
    "\n",
    "# Save to CSV\n",
    "Map_Trans.to_csv(\"/workspaces/phonepe/csv_data/map_transaction_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV file saved as 'map_transaction_data.csv'\")\n",
    "Map_Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8372d47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file saved as 'map_user_data.csv'\n"
     ]
    }
   ],
   "source": [
    "#Map_User\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to map user data\n",
    "path = \"/workspaces/phonepe/pulse/data/map/user/hover/country/india/state\"\n",
    "Map_state_list = os.listdir(path)\n",
    "\n",
    "# Prepare dictionary for DataFrame\n",
    "clm = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'District_State_Name': [],\n",
    "    'Registered_users': [],\n",
    "    'App_opens': []\n",
    "}\n",
    "\n",
    "for i in Map_state_list:\n",
    "    p_i = os.path.join(path, i)\n",
    "    if not os.path.exists(p_i):\n",
    "        print(f\"⚠️ Skipping missing state folder: {p_i}\")\n",
    "        continue\n",
    "\n",
    "    Map_yr = os.listdir(p_i)\n",
    "    for j in Map_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        if not os.path.exists(p_j):\n",
    "            continue\n",
    "\n",
    "        Map_yr_list = os.listdir(p_j)\n",
    "        for k in Map_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            if not os.path.isfile(p_k):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(p_k, 'r') as Data:\n",
    "                    D = json.load(Data)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {p_k}: {e}\")\n",
    "                continue\n",
    "\n",
    "            hover_data = D.get('data', {}).get('hoverData', {})\n",
    "            if not hover_data:\n",
    "                print(f\"⚠️ No 'hoverData' in: {p_k}\")\n",
    "                continue\n",
    "\n",
    "            for name, values in hover_data.items():\n",
    "                registered_users = values.get('registeredUsers', 0)\n",
    "                app_opens = values.get('appOpens', 0)\n",
    "\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(int(k.strip('.json')))\n",
    "                clm['District_State_Name'].append(name)\n",
    "                clm['Registered_users'].append(registered_users)\n",
    "                clm['App_opens'].append(app_opens)\n",
    "\n",
    "# Create DataFrame\n",
    "Map_User = pd.DataFrame(clm)\n",
    "\n",
    "# Save to CSV\n",
    "Map_User.to_csv(\"/workspaces/phonepe/csv_data/map_user_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV file saved as 'map_user_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96492815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map-Insurance\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to map insurance data\n",
    "path = \"/workspaces/phonepe/pulse/data/map/insurance/hover/country/india/state\"\n",
    "Map_state_list = os.listdir(path)\n",
    "\n",
    "# Prepare dictionary for DataFrame\n",
    "clm = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'District_State_Name': [],\n",
    "    'Count': [],\n",
    "    'Amount': []\n",
    "}\n",
    "\n",
    "for i in Map_state_list:  # State loop\n",
    "    p_i = os.path.join(path, i)\n",
    "    if not os.path.exists(p_i):\n",
    "        print(f\"⚠️ Skipping missing state folder: {p_i}\")\n",
    "        continue\n",
    "\n",
    "    Map_yr = os.listdir(p_i)\n",
    "    for j in Map_yr:  # Year loop\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        if not os.path.exists(p_j):\n",
    "            continue\n",
    "\n",
    "        Map_yr_list = os.listdir(p_j)\n",
    "        for k in Map_yr_list:  # Quarter loop\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            quarter_num = int(k.strip('.json'))\n",
    "\n",
    "            if not os.path.isfile(p_k):\n",
    "                print(f\"⚠️ Missing file: {p_k} → Adding placeholder\")\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(quarter_num)\n",
    "                clm['District_State_Name'].append(i)\n",
    "                clm['Count'].append(0)\n",
    "                clm['Amount'].append(0)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(p_k, 'r') as Data:\n",
    "                    D = json.load(Data)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {p_k}: {e}\")\n",
    "                continue\n",
    "\n",
    "            hover_data_list = D.get('data', {}).get('hoverDataList', [])\n",
    "            if not hover_data_list:\n",
    "                print(f\"⚠️ No 'hoverDataList' in: {p_k} → Adding placeholder\")\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(quarter_num)\n",
    "                clm['District_State_Name'].append(i)\n",
    "                clm['Count'].append(0)\n",
    "                clm['Amount'].append(0)\n",
    "                continue\n",
    "\n",
    "            for entry in hover_data_list:\n",
    "                name = entry.get('name', '')\n",
    "                metric = entry.get('metric', [{}])[0]\n",
    "                count = metric.get('count', 0)\n",
    "                amount = metric.get('amount', 0)\n",
    "\n",
    "                clm['State'].append(i)\n",
    "                clm['Year'].append(j)\n",
    "                clm['Quarter'].append(quarter_num)\n",
    "                clm['District_State_Name'].append(name)\n",
    "                clm['Count'].append(count)\n",
    "                clm['Amount'].append(amount)\n",
    "\n",
    "# Create DataFrame\n",
    "Map_Insurance = pd.DataFrame(clm)\n",
    "\n",
    "# Save to CSV\n",
    "Map_Insurance.to_csv(\"/workspaces/phonepe/csv_data/map_insurance_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV file saved as 'map_insurance_data.csv'\")\n",
    "Map_Insurance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a894e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved with 18295 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Entity_level</th>\n",
       "      <th>Entity_Name</th>\n",
       "      <th>Transaction_Count</th>\n",
       "      <th>Transaction_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>districts</td>\n",
       "      <td>gautam buddha nagar</td>\n",
       "      <td>157681545</td>\n",
       "      <td>1.509482e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>districts</td>\n",
       "      <td>ghaziabad</td>\n",
       "      <td>79274230</td>\n",
       "      <td>1.069629e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>districts</td>\n",
       "      <td>lucknow</td>\n",
       "      <td>75332865</td>\n",
       "      <td>9.674255e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>districts</td>\n",
       "      <td>prayagraj</td>\n",
       "      <td>41130090</td>\n",
       "      <td>5.561937e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>districts</td>\n",
       "      <td>agra</td>\n",
       "      <td>36064514</td>\n",
       "      <td>5.751819e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18290</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>pincodes</td>\n",
       "      <td>122051</td>\n",
       "      <td>2218449</td>\n",
       "      <td>2.493078e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18291</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>pincodes</td>\n",
       "      <td>121001</td>\n",
       "      <td>1991396</td>\n",
       "      <td>3.435442e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18292</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>pincodes</td>\n",
       "      <td>121102</td>\n",
       "      <td>1973371</td>\n",
       "      <td>3.709175e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18293</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>pincodes</td>\n",
       "      <td>122004</td>\n",
       "      <td>1817807</td>\n",
       "      <td>2.080396e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18294</th>\n",
       "      <td>haryana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>pincodes</td>\n",
       "      <td>121002</td>\n",
       "      <td>1658861</td>\n",
       "      <td>2.966291e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18295 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               State  Year  Quarter Entity_level          Entity_Name  \\\n",
       "0      uttar-pradesh  2023        2    districts  gautam buddha nagar   \n",
       "1      uttar-pradesh  2023        2    districts            ghaziabad   \n",
       "2      uttar-pradesh  2023        2    districts              lucknow   \n",
       "3      uttar-pradesh  2023        2    districts            prayagraj   \n",
       "4      uttar-pradesh  2023        2    districts                 agra   \n",
       "...              ...   ...      ...          ...                  ...   \n",
       "18290        haryana  2020        4     pincodes               122051   \n",
       "18291        haryana  2020        4     pincodes               121001   \n",
       "18292        haryana  2020        4     pincodes               121102   \n",
       "18293        haryana  2020        4     pincodes               122004   \n",
       "18294        haryana  2020        4     pincodes               121002   \n",
       "\n",
       "       Transaction_Count  Transaction_Amount  \n",
       "0              157681545        1.509482e+11  \n",
       "1               79274230        1.069629e+11  \n",
       "2               75332865        9.674255e+10  \n",
       "3               41130090        5.561937e+10  \n",
       "4               36064514        5.751819e+10  \n",
       "...                  ...                 ...  \n",
       "18290            2218449        2.493078e+09  \n",
       "18291            1991396        3.435442e+09  \n",
       "18292            1973371        3.709175e+09  \n",
       "18293            1817807        2.080396e+09  \n",
       "18294            1658861        2.966291e+09  \n",
       "\n",
       "[18295 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top-Transaction\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to top transactions state folder\n",
    "path = \"/workspaces/phonepe/pulse/data/top/transaction/country/india/state/\"\n",
    "\n",
    "# Empty structure\n",
    "clm = {\n",
    "    'State': [],\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'Entity_level': [],    # states, districts, or pincodes\n",
    "    'Entity_Name': [],\n",
    "    'Transaction_Count': [],\n",
    "    'Transaction_Amount': []\n",
    "}\n",
    "\n",
    "# Loop over states\n",
    "for state in os.listdir(path):\n",
    "    state_path = os.path.join(path, state)\n",
    "    if not os.path.isdir(state_path):\n",
    "        continue\n",
    "\n",
    "    # Loop over years\n",
    "    for year in os.listdir(state_path):\n",
    "        year_path = os.path.join(state_path, year)\n",
    "        if not os.path.isdir(year_path):\n",
    "            continue\n",
    "\n",
    "        # Loop over quarters\n",
    "        for file in os.listdir(year_path):\n",
    "            if not file.endswith(\".json\"):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(year_path, file)\n",
    "            quarter = int(file.strip(\".json\"))\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # Extract each section\n",
    "                for section in ['states', 'districts', 'pincodes']:\n",
    "                    if section in data['data'] and data['data'][section]:\n",
    "                        for entry in data['data'][section]:\n",
    "                            clm['State'].append(state)\n",
    "                            clm['Year'].append(year)\n",
    "                            clm['Quarter'].append(quarter)\n",
    "                            clm['Entity_level'].append(section)\n",
    "                            clm['Entity_Name'].append(entry['entityName'])\n",
    "                            clm['Transaction_Count'].append(entry['metric']['count'])\n",
    "                            clm['Transaction_Amount'].append(entry['metric']['amount'])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error in {file_path}: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "Top_Trans = pd.DataFrame(clm)\n",
    "\n",
    "# Save CSV\n",
    "Top_Trans.to_csv(\"/workspaces/phonepe/csv_data/top_transaction_data.csv\", index=False)\n",
    "\n",
    "print(f\"✅ CSV saved with {len(Top_Trans)} rows\")\n",
    "Top_Trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "581a852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved with 10000 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>RegisteredUsers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>None</td>\n",
       "      <td>201301</td>\n",
       "      <td>883262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>None</td>\n",
       "      <td>201009</td>\n",
       "      <td>490549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>None</td>\n",
       "      <td>201102</td>\n",
       "      <td>438404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>None</td>\n",
       "      <td>201307</td>\n",
       "      <td>390571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>None</td>\n",
       "      <td>201318</td>\n",
       "      <td>371461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>None</td>\n",
       "      <td>122002</td>\n",
       "      <td>176881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>None</td>\n",
       "      <td>121102</td>\n",
       "      <td>169232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>None</td>\n",
       "      <td>124001</td>\n",
       "      <td>161912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>None</td>\n",
       "      <td>123401</td>\n",
       "      <td>160526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>None</td>\n",
       "      <td>122004</td>\n",
       "      <td>150225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Quarter          State District Pincode  RegisteredUsers\n",
       "0     2023        2  uttar-pradesh     None  201301           883262\n",
       "1     2023        2  uttar-pradesh     None  201009           490549\n",
       "2     2023        2  uttar-pradesh     None  201102           438404\n",
       "3     2023        2  uttar-pradesh     None  201307           390571\n",
       "4     2023        2  uttar-pradesh     None  201318           371461\n",
       "...    ...      ...            ...      ...     ...              ...\n",
       "9995  2020        4        haryana     None  122002           176881\n",
       "9996  2020        4        haryana     None  121102           169232\n",
       "9997  2020        4        haryana     None  124001           161912\n",
       "9998  2020        4        haryana     None  123401           160526\n",
       "9999  2020        4        haryana     None  122004           150225\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top user\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path for user data (map-level data)\n",
    "path = \"/workspaces/phonepe/pulse/data/top/user/country/india/state\"\n",
    "state_list = os.listdir(path)  # List of states\n",
    "\n",
    "# Dictionary for collected data\n",
    "clm = {\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'State': [],\n",
    "    'District': [],\n",
    "    'Pincode': [],\n",
    "    'RegisteredUsers': []\n",
    "}\n",
    "\n",
    "for state in state_list:\n",
    "    state_path = os.path.join(path, state)\n",
    "    year_list = os.listdir(state_path)\n",
    "\n",
    "    for year in year_list:\n",
    "        year_path = os.path.join(state_path, year)\n",
    "        quarter_list = os.listdir(year_path)\n",
    "\n",
    "        for quarter in quarter_list:\n",
    "            file_path = os.path.join(year_path, quarter)\n",
    "\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                # Check if the structure exists\n",
    "                if \"data\" in data and \"pincodes\" in data[\"data\"]:\n",
    "                    for pincode_info in data[\"data\"][\"pincodes\"]:\n",
    "                        clm['Year'].append(year)\n",
    "                        clm['Quarter'].append(int(quarter.strip('.json')))\n",
    "                        clm['State'].append(state)\n",
    "                        clm['District'].append(pincode_info.get('districtName', None))\n",
    "                        clm['Pincode'].append(pincode_info.get('name', None))\n",
    "                        clm['RegisteredUsers'].append(pincode_info.get('registeredUsers', None))\n",
    "\n",
    "# Create DataFrame\n",
    "Top_Users = pd.DataFrame(clm)\n",
    "\n",
    "# Save CSV\n",
    "Top_Users.to_csv(\"/workspaces/phonepe/csv_data/top_user_data.csv\", index=False)\n",
    "\n",
    "print(f\"✅ CSV saved with {len(Top_Users)} rows\")\n",
    "Top_Users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c63558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved with 5608 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>State</th>\n",
       "      <th>EntityName</th>\n",
       "      <th>Type</th>\n",
       "      <th>Count</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>gautam buddha nagar</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>ghaziabad</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>lucknow</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>kanpur nagar</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>uttar-pradesh</td>\n",
       "      <td>meerut</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>sonipat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5604</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>palwal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>mahendragarh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>panipat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>haryana</td>\n",
       "      <td>bhiwani</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5608 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Quarter          State           EntityName  Type Count Amount\n",
       "0     2023        2  uttar-pradesh  gautam buddha nagar  None  None   None\n",
       "1     2023        2  uttar-pradesh            ghaziabad  None  None   None\n",
       "2     2023        2  uttar-pradesh              lucknow  None  None   None\n",
       "3     2023        2  uttar-pradesh         kanpur nagar  None  None   None\n",
       "4     2023        2  uttar-pradesh               meerut  None  None   None\n",
       "...    ...      ...            ...                  ...   ...   ...    ...\n",
       "5603  2020        4        haryana              sonipat  None  None   None\n",
       "5604  2020        4        haryana               palwal  None  None   None\n",
       "5605  2020        4        haryana         mahendragarh  None  None   None\n",
       "5606  2020        4        haryana              panipat  None  None   None\n",
       "5607  2020        4        haryana              bhiwani  None  None   None\n",
       "\n",
       "[5608 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top Insurance\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path for your new data (adjust to your actual folder)\n",
    "path = \"/workspaces/phonepe/pulse/data/top/insurance/country/india/state\"\n",
    "state_list = os.listdir(path)  # List of states\n",
    "\n",
    "# Dictionary for collected data\n",
    "clm = {\n",
    "    'Year': [],\n",
    "    'Quarter': [],\n",
    "    'State': [],\n",
    "    'EntityName': [],\n",
    "    'Type': [],\n",
    "    'Count': [],\n",
    "    'Amount': []\n",
    "}\n",
    "\n",
    "for state in state_list:\n",
    "    state_path = os.path.join(path, state)\n",
    "    year_list = os.listdir(state_path)\n",
    "\n",
    "    for year in year_list:\n",
    "        year_path = os.path.join(state_path, year)\n",
    "        quarter_list = os.listdir(year_path)\n",
    "\n",
    "        for quarter in quarter_list:\n",
    "            file_path = os.path.join(year_path, quarter)\n",
    "\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                # Check if the structure exists\n",
    "                if \"data\" in data and \"districts\" in data[\"data\"]:\n",
    "                    for district_info in data[\"data\"][\"districts\"]:\n",
    "                        clm['Year'].append(year)\n",
    "                        clm['Quarter'].append(int(quarter.strip('.json')))\n",
    "                        clm['State'].append(state)\n",
    "                        clm['EntityName'].append(district_info.get('entityName', None))\n",
    "                        clm['Type'].append(district_info.get('type', None))\n",
    "                        clm['Count'].append(district_info.get('count', None))\n",
    "                        clm['Amount'].append(district_info.get('amount', None))\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "Top_Insu = pd.DataFrame(clm)\n",
    "\n",
    "# Save CSV\n",
    "Top_Insu.to_csv(\"/workspaces/phonepe/csv_data/top_insu_data.csv\", index=False)\n",
    "\n",
    "print(f\"✅ CSV saved with {len(Top_Insu)} rows\")\n",
    "Top_Insu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6268b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in ./.venv/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: psycopg2 in ./.venv/lib/python3.12/site-packages (2.9.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary pandas\n",
    "!pip install psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 05:43:00.717 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.718 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.866 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /workspaces/phonepe/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-08-15 05:43:00.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.868 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.869 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.871 Session state does not function when running a script without `streamlit run`\n",
      "2025-08-15 05:43:00.871 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.872 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.872 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.874 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:00.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "/tmp/ipykernel_3019/3682356228.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "2025-08-15 05:43:02.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:02.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:02.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:02.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-15 05:43:02.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Connecting Database\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "# 📂 Folder where CSVs are stored\n",
    "CSV_FOLDER = \"/workspaces/phonepe/csv_data\"\n",
    "\n",
    "# PostgreSQL connection details — update as needed\n",
    "DB_HOST = \"dpg-d2c1kier433s73a8a7p0-a.singapore-postgres.render.com\"\n",
    "DB_NAME = \"phonepe_data\"\n",
    "DB_USER = \"phonepe_m8o9_user\"\n",
    "DB_PASS = \"zkVsinSHsjx0wachLF0CJEL7AJP1ySKa\"\n",
    "DB_PORT = 5432\n",
    "\n",
    "MAX_BIGINT = 9223372036854775807  # PostgreSQL BIGINT max value\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        database=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    print(\"✅ Database connection established.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Database connection failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def safe_bigint(value):\n",
    "    \"\"\"Return None if value exceeds BIGINT max limit, else return as is.\"\"\"\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return None\n",
    "        ivalue = int(value)\n",
    "        if ivalue > MAX_BIGINT or ivalue < -MAX_BIGINT - 1:\n",
    "            return None\n",
    "        return ivalue\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def insert_csv_to_table(csv_path, table_name, sql_columns):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [col.strip().lower().replace(' ', '_').replace('/', '_') for col in df.columns]\n",
    "\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        row_data = []\n",
    "        for col in sql_columns:\n",
    "            val = row[col]\n",
    "            if col in ['transaction_count', 'registered_users', 'count', 'registeredusers']:\n",
    "                val = safe_bigint(val)\n",
    "            row_data.append(val)\n",
    "        data.append(tuple(row_data))\n",
    "\n",
    "    columns_str = ', '.join(sql_columns)\n",
    "    sql = f\"INSERT INTO {table_name} ({columns_str}) VALUES %s\"\n",
    "    psycopg2.extras.execute_values(cur, sql, data)\n",
    "    conn.commit()\n",
    "    print(f\"✅ Data inserted into '{table_name}'.\")\n",
    "\n",
    "# CSV to table mapping\n",
    "csv_to_table_map = [\n",
    "    (\"aggregated_transaction_data.csv\", \"aggregated_transaction_data\", ['state', 'year', 'quarter', 'transaction_type', 'transaction_count', 'transaction_amount']),\n",
    "    (\"aggregated_insurance_data.csv\", \"aggregated_insurance_data\", ['state', 'year', 'quarter', 'transaction_type', 'transaction_count', 'transaction_amount']),\n",
    "    (\"aggregated_user_data.csv\", \"aggregated_user_data\", ['state', 'year', 'quarter', 'brand', 'transaction_count', 'transaction_percentage']),\n",
    "    (\"map_transaction_data.csv\", \"map_transaction_data\", ['state', 'year', 'quarter', 'district_state_name', 'transaction_count', 'transaction_amount']),\n",
    "    (\"map_user_data.csv\", \"map_user_data\", ['state', 'year', 'quarter', 'district_state_name', 'registered_users', 'app_opens']),\n",
    "    (\"map_insurance_data.csv\", \"map_insurance_data\", ['state', 'year', 'quarter', 'district_state_name', 'count', 'amount']),\n",
    "    (\"top_transaction_data.csv\", \"top_transaction_data\", ['state', 'year', 'quarter', 'entity_level', 'entity_name', 'transaction_count', 'transaction_amount']),\n",
    "    (\"top_user_data.csv\", \"top_user_data\", ['year', 'quarter', 'state', 'district', 'pincode', 'registeredusers']),\n",
    "    (\"top_insu_data.csv\", \"top_insurance_data\", ['year', 'quarter', 'state', 'entityname', 'type', 'count', 'amount']),\n",
    "]\n",
    "\n",
    "# Process CSV files\n",
    "for csv_file, table, cols in csv_to_table_map:\n",
    "    csv_path = os.path.join(CSV_FOLDER, csv_file)\n",
    "    if not os.path.isfile(csv_path):\n",
    "        print(f\"⚠️ CSV file not found: {csv_file}, skipping.\")\n",
    "        continue\n",
    "    insert_csv_to_table(csv_path, table, cols)\n",
    "\n",
    "# Close DB connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"✅ All data inserted and connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4a58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2b91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003d665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972c00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
